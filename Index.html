<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generative Counterpoint with Reactive TV Static</title>
    <style>
        body {
            margin: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: black;
            color: white;
            font-family: Arial, sans-serif;
        }

        canvas {
            margin-top: 20px;
            background-color: black;
        }

        button {
            padding: 15px 30px;
            font-size: 18px;
            background-color: #444;
            border: none;
            color: white;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        button:hover {
            background-color: #666;
        }
    </style>
</head>
<body>
    <button onclick="startMusic()">mourn</button>
    <canvas id="staticCanvas" width="640" height="360"></canvas>

    <script>
        let audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let isPlaying = false;
        let animationFrame;
        const canvas = document.getElementById('staticCanvas');
        const ctx = canvas.getContext('2d');
        const scale = [0, 2, 4, 5, 7, 9, 11, 12]; // Major scale intervals
        const baseFrequency = 440; // A4
        const noteLengths = [0.5, 1, 2, 4]; // Adjusted for slower tempo
        const tempo = 90; // BPM
        const harmonyIntervals = [0, 3, 4, 7, 9]; // Unison, third, fourth, fifth, sixth
        const octaveOffsets = [-36, -24, -12, 0, 12]; // Octave offsets with a bass voice
        const voices = [[], [], [], [], []]; // Tracks the steps of the scale for each voice
        const gainNodes = [];

        function fmSynthesis(frequency, voiceIndex) {
            // Create the oscillators
            const carrier1 = audioContext.createOscillator();
            const carrier2 = audioContext.createOscillator();
            const modulator = audioContext.createOscillator();
            const modGain = audioContext.createGain();

            // Detune the second carrier slightly for a richer sound
            carrier1.frequency.value = frequency;
            carrier2.frequency.value = frequency * 1.005; // Slight detune

            // Apply modulation
            modulator.frequency.value = frequency * 2;
            modGain.gain.value = frequency / 2;
            modulator.connect(modGain);
            modGain.connect(carrier1.frequency);
            modGain.connect(carrier2.frequency);

            // Create a low-pass filter for warmth
            const filter = audioContext.createBiquadFilter();
            filter.type = 'lowpass';
            filter.frequency.value = 1200; // Cutoff frequency for warmth

            // Envelope for gradual attack
            const envelope = audioContext.createGain();
            envelope.gain.setValueAtTime(0, audioContext.currentTime);
            envelope.gain.linearRampToValueAtTime(1, audioContext.currentTime + 0.5); // 0.5s attack

            // Reverb effect
            const reverb = audioContext.createConvolver();
            reverb.buffer = createReverbBuffer(audioContext);

            // Delay effect
            const delay = audioContext.createDelay();
            delay.delayTime.value = 0.3; // 300ms delay

            // Vibrato effect
            const vibrato = audioContext.createOscillator();
            const vibratoGain = audioContext.createGain();
            vibrato.frequency.value = 5; // 5 Hz vibrato
            vibratoGain.gain.value = 10; // 10 Hz deviation
            vibrato.connect(vibratoGain);
            vibratoGain.connect(carrier1.frequency);
            vibratoGain.connect(carrier2.frequency);

            // Connect nodes
            carrier1.connect(envelope);
            carrier2.connect(envelope);
            envelope.connect(filter);
            filter.connect(delay);
            delay.connect(reverb);
            reverb.connect(audioContext.destination);

            // Store the gain node for amplitude tracking
            gainNodes[voiceIndex] = envelope;

            // Start oscillators and vibrato
            carrier1.start();
            carrier2.start();
            modulator.start();
            vibrato.start();

            return { carrier1, carrier2, modulator, envelope, vibrato };
        }

        function createReverbBuffer(context) {
            const length = context.sampleRate * 2.5; // 2.5 seconds reverb
            const impulse = context.createBuffer(2, length, context.sampleRate);
            for (let i = 0; i < length; i++) {
                const n = length - i;
                impulse.getChannelData(0)[i] = (Math.random() * 2 - 1) * (n / length);
                impulse.getChannelData(1)[i] = (Math.random() * 2 - 1) * (n / length);
            }
            return impulse;
        }

        function playFlute(frequency, duration, voiceIndex) {
            const { carrier1, carrier2, modulator, envelope, vibrato } = fmSynthesis(frequency, voiceIndex);

            // Release the note by fading out the envelope
            envelope.gain.setValueAtTime(1, audioContext.currentTime + duration - 0.1);
            envelope.gain.linearRampToValueAtTime(0, audioContext.currentTime + duration);

            // Stop oscillators and vibrato after the note ends
            carrier1.stop(audioContext.currentTime + duration);
            carrier2.stop(audioContext.currentTime + duration);
            modulator.stop(audioContext.currentTime + duration);
            vibrato.stop(audioContext.currentTime + duration);
        }

        function getFrequency(step, octaveOffset = 0) {
            return baseFrequency * Math.pow(2, (scale[step % scale.length] + octaveOffset) / 12);
        }

        function getHarmoniousStep(mainStep, previousStep, voiceIndex) {
            let candidateSteps = harmonyIntervals.map(interval => (mainStep + interval) % scale.length);
            candidateSteps = candidateSteps.filter(step => step !== previousStep && !voices[voiceIndex].includes(step));

            return candidateSteps.length > 0 
                ? candidateSteps[Math.floor(Math.random() * candidateSteps.length)] 
                : mainStep; // Fallback to unison if no candidates are valid
        }

        function getRandomNoteLength() {
            return noteLengths[Math.floor(Math.random() * noteLengths.length)];
        }

        function playMelody(voiceIndex, previousStep = 0) {
            if (!isPlaying) return;

            const mainStep = voices[0][voices[0].length - 1] || 0;
            const step = voiceIndex === 0 
                ? getRandomStep(mainStep) 
                : getHarmoniousStep(mainStep, previousStep, voiceIndex);

            voices[voiceIndex].push(step);
            const frequency = getFrequency(step, octaveOffsets[voiceIndex]);
            const duration = getRandomNoteLength();

            playFlute(frequency, duration, voiceIndex);

            setTimeout(() => {
                playMelody(voiceIndex, step);
            }, (duration * 60 / tempo) * 1000);
        }

        function getRandomStep(previousStep) {
            const direction = Math.random() > 0.5 ? 1 : -1;
            return (previousStep + direction + scale.length) % scale.length;
        }

        function startMusic() {
            if (isPlaying) return;

            isPlaying = true;

            // Clear previous voices
            voices.forEach((voice, index) => {
                voices[index] = [];
            });

            // Start the visual animation
            animateStatic();

            // Main melody
            playMelody(0);

            // Counterpoint voices, including the bass
            for (let i = 1; i <= 4; i++) { // Note: 4th index is now the bass voice
                setTimeout(() => playMelody(i), i * 1000);
            }
        }

        function stopMusic() {
            isPlaying = false;
            cancelAnimationFrame(animationFrame);
            audioContext.close().then(() => {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            });
        }

        function animateStatic() {
            if (!isPlaying) return;

            const imageData = ctx.createImageData(canvas.width, canvas.height);
            const data = imageData.data;

            // Generate TV static effect
            for (let i = 0; i < data.length; i += 4) {
                const brightness = Math.random() * 255;
                data[i] = data[i + 1] = data[i + 2] = brightness;
                data[i + 3] = 255; // Full opacity
            }

            // Overlay amplitude-based modifications
            const avgAmplitude = gainNodes

.reduce((sum, gainNode) => sum + gainNode.gain.value, 0) / gainNodes.length;
            const effectStrength = avgAmplitude * 50;

            for (let i = 0; i < data.length; i += 4) {
                data[i] += effectStrength * (Math.random() - 0.5);
                data[i + 1] += effectStrength * (Math.random() - 0.5);
                data[i + 2] += effectStrength * (Math.random() - 0.5);
            }

            ctx.putImageData(imageData, 0, 0);

            // Continue the animation
            animationFrame = requestAnimationFrame(animateStatic);
        }
    </script>
</body>
</html>
